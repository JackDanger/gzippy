# gzippy — The Fastest Parallel Gzip

## Prime Directive

**gzippy aims to be the fastest gzip implementation in existence.**

## Production Code Paths (Feb 2026)

### Compression

| Levels | Library | Strategy |
|--------|---------|----------|
| L1-L5 | libdeflate | Parallel independent BGZF blocks |
| L6-L9 | zlib-ng | Pipelined with dictionary (single stream) |
| L10-L12 | libdeflate L10-12 | Parallel independent, 512KB blocks |

### Decompression

| Input Type | Path | Library |
|------------|------|---------|
| BGZF (gzippy output) | `bgzf::decompress_bgzf_parallel` | libdeflate FFI, parallel at any T |
| Multi-member | `bgzf::decompress_multi_member_parallel` | libdeflate FFI, parallel |
| Single-member x86_64 | `isal_decompress::decompress_gzip_stream` | ISA-L direct FFI |
| Single-member arm64 | `decompress_single_member_libdeflate` | libdeflate FFI |

### Key Production Modules

| File | Purpose |
|------|---------|
| `decompression.rs` | Entry point, format detection, routing |
| `bgzf.rs` | BGZF/multi-member parallel decompression |
| `isal_decompress.rs` | ISA-L streaming inflate (x86_64 only, direct `isal_sys` FFI) |
| `libdeflate_ext.rs` | libdeflate FFI wrappers |
| `compression.rs` | Compression entry point |
| `parallel_compress.rs` | Parallel BGZF compression engine |
| `pipelined_compress.rs` | Pipelined L6-L9 compression |
| `isal_compress.rs` | ISA-L compression (x86_64) |

### Experimental (NOT in CLI hot path)

These modules exist for research but are not wired into the shipping binary:
- `consume_first_decode.rs` — pure Rust inflate (~91% of libdeflate on ARM)
- `speculative_parallel.rs` — experimental single-member parallel
- `marker_decode.rs` — marker-based speculative decoding
- `vector_huffman.rs` — SIMD Huffman infrastructure
- `unified_table.rs`, `packed_lut.rs`, `jit_decode.rs`, etc.

## Performance: 41W / 19L (Feb 2026)

See `.cursor/rules/performance-analysis.mdc` for the full breakdown.

### Remaining 19 Losses

| Category | Count | Gap | Root Cause |
|----------|-------|-----|------------|
| x86 T1 decompress near-parity | 4 | <1% | Measurement noise |
| Tmax single-member parallel | 8 | -18% to -41% | No single-member parallel decompress |
| L1 T1 compress vs igzip | 2 | -62% to -73% | igzip AVX-512 hand-tuned assembly |
| L1/L6 Tmax compress scaling | 5 | -10% to -39% | pigz thread scaling |

## Absolute Rules

### Performance is unconditional

- Never accept a clippy/lint change in a hot path without verifying identical codegen.
- Use `#[allow(clippy::...)]` when clippy and performance conflict.
- Benchmark BEFORE and AFTER every change on real data.
- Simulation benchmarks lie — always validate end-to-end.

### No new libdeflate FFI in hot paths

Existing FFI is fine. Don't add new call sites — the long-term goal is pure Rust.

### Benchmark honesty

- `bench_production_inflate` in `bgzf.rs` = actual shipped code
- `bench_cf_silesia` in `consume_first_decode.rs` = experimental pure Rust
- CI benchmarks must exercise the same code that ships in binaries

## Proven Strategies

### What works

1. BGZF block structure for parallel decompression
2. Pre-allocated output based on ISIZE trailer
3. Lock-free parallel writes via UnsafeCell for disjoint regions
4. Direct ISA-L FFI (bypassing wrapper crates) for x86 decompression
5. 1MB streaming output buffer (avoids page fault overhead)
6. Statically-linked dependencies for portability
7. RAM-backed I/O (/dev/shm) for benchmarks — reveals true CPU speed

### What doesn't work

1. **Speculative parallel decode**: -15% to -86% regression on real data
2. **Two-pass parallel (scan + re-decode)**: scan costs as much as full decode
3. **Finding deflate block boundaries**: success rate <5%
4. **Pre-allocated full output + single write_all**: 50K page faults (55ms overhead)
5. **isal-rs Decoder wrapper**: 16KB internal buffer copies cost 2-8%
6. **Passing `&data[start..]` to chunk decoders**: forces decoding entire tail
7. **Simulation benchmarks**: always overestimate gains
8. **Micro-optimizations in decode loop**: LLVM already optimizes well
9. **Internal fallback to slow paths**: must return Err, let caller choose fast fallback

## Architecture Notes

### Format Detection

```
BGZF? → decompress_bgzf_parallel (parallel even at T1)
Multi-member? → decompress_multi_member_parallel / sequential fallback
Single-member x86? → ISA-L direct FFI streaming
Single-member arm? → libdeflate FFI
```

Key: pigz output is SINGLE-MEMBER gzip (not multi-member). This was a critical
discovery — pigz Tmax losses are the same root cause as gzip Tmax losses.

### ISA-L Integration (x86_64 only)

`isal_decompress::decompress_gzip_stream` calls `isal_sys::isal_inflate()` directly,
pointing at mmap'd input with a 1MB output buffer. This matches igzip's internal
loop exactly — zero overhead from Rust wrapper crates.

Gated behind `#[cfg(all(feature = "isal-compression", target_arch = "x86_64"))]`.

### Parallel Decompression

BGZF blocks have embedded sizes in the extra field. This enables:
1. Parse all block headers (sizes known upfront)
2. Pre-allocate exact output from ISIZE trailers
3. Parallel inflate into disjoint slices (UnsafeCell, no locks)
4. Single write_all of the full output

### libdeflate's Key Design Patterns

- **Fastloop/generic loop split**: Fastloop runs with buffer margin (unsafe copies OK),
  generic loop runs near boundaries (exact-length copies required)
- **Entry format**: single u32 packs symbol + bits + extras
- **Branchless refill**: unconditional load + pointer math
- **Multi-literal batching**: decode 2-3 literals per iteration

## Build

```toml
[profile.release]
opt-level = 3
lto = "fat"
codegen-units = 1
panic = "abort"
strip = true
```

Feature flags:
- `isal-compression`: Enables ISA-L for x86_64 (compression AND decompression)
- Binary is fully self-contained (statically linked)

## Testing & CI

```bash
timeout 120 cargo test --release           # Always use timeouts
cargo clippy --all-targets --all-features -- -D warnings
cargo fmt --check
```

Pre-commit hook runs `cargo fmt --check` and `cargo clippy`.

Cloud fleet (`gzippy-dev cloud bench`) is the authoritative benchmark.
Local benchmarks are for rapid iteration only.

Set `GZIPPY_DEBUG=1` for timing diagnostics.

---
description: CI-driven performance workflow — CI is the source of truth, not local benchmarks
alwaysApply: true
---

# Performance Workflow: CI Is the Source of Truth

## Core Principle

**Never trust local benchmarks for final decisions.** GHA CI runs on both x86_64 (EPYC)
and arm64 (Graviton) with all datasets, archive types, thread configs, and competitors.
Local runs are useful for rapid iteration but CI is authoritative.

## The Loop

```
gzippy-dev ci triage          # 1. What gaps remain?
# ... make ONE focused code change ...
gzippy-dev ci push            # 2. Push → CI → auto-triage + vs-main
gzippy-dev ci vs-main         # 3. Check anytime: did branch help or hurt?
```

## Current Status: ~92% Effective Win Rate (Feb 20 2026)

**Effective win rate: 94.3%** (up from 83% at start of session)
- ARCHITECTURE: 4 gaps (silesia Tmax vs rapidgzip only, 10-16%)
- SIMD: 3 gaps (L1 compression vs igzip, 4-50% but worst is CI noise)
- ACTIONABLE: 0 gaps
- NOISE: 27 gaps (properly thresholded by platform/dataset)

Key wins from latest CI run (perf/bgzf-t1-fast-path vs main):
- `silesia-bgzf Tmax x86`: +10.1% (314.8 → 346.5 MB/s, now BEATS rapidgzip by 6.6%)
- `silesia-bgzf T1 x86`: +10.0% (234.0 → 257.5 MB/s)
- `silesia-gzip T1 x86`: +4.8% (254.5 → 266.6 MB/s)
- `silesia-pigz Tmax x86`: +7.6% (239.5 → 257.6 MB/s)

## What We Learned (Feb 20 2026)

### Noise Thresholds Must Vary by Context

| Context | Threshold | Why |
|---|---|---|
| arm64 + small files | 25% | CI shows 24%+ swings between identical runs (observed: 164→125 MB/s, same code) |
| arm64 + silesia | 8% | Better but still noisy |
| x86 + small files | 5% | Moderate variance from startup overhead |
| x86 + silesia | 3% | Most stable measurement |

The old flat 2% threshold miscategorized arm64 noise as ACTIONABLE, wasting effort.

### Pigz Decompresses Sequentially (Even at Tmax)

Pigz ignores `-p` for decompression. So Tmax gaps vs pigz on single-member files
are NOT architecture gaps — both tools decompress sequentially. Only rapidgzip does
parallel single-member decompression. The triage now only classifies Tmax gaps vs
rapidgzip as ARCHITECTURE.

### pigz Output Is Single-Member

pigz 2.8 creates **single-member** gzip output from stdin (even with `-p4`). Our
`is_likely_multi_member` correctly returns false. The gaps vs rapidgzip on `silesia-pigz`
are genuine architecture gaps, not detection bugs.

### Two-Pass Parallel Does NOT Beat Sequential

Tested: scan pass (pure Rust inflate) + parallel re-decode vs libdeflate FFI sequential.
Result: **32% SLOWER** on ARM (650 MB/s vs 960 MB/s).

Root cause: scan pass does full decode work (~1x), parallel pass adds ~0.25x. Total 1.25x
work at 90% of libdeflate speed = net throughput 72% of sequential. Break-even requires
11+ threads; CI has only 4.

The ONLY viable parallel single-member approach is rapidgzip-style speculative decode
(no scan pass). This remains a major feature gap.

### stdin mmap Helps When Stdin Is a Regular File

CI benchmark pipes files via `subprocess.run(cmd, stdin=fin, stdout=fout)`. Python passes
the real fd, so gzippy can mmap stdin instead of copying 77MB into a Vec. Saves allocation
+ copy overhead.

### Raw Deflate Is Faster Than gzip_decompress_ex

For trusted BGZF blocks, call `libdeflate_deflate_decompress` directly on the raw deflate
data. Skips per-block: gzip header parsing, CRC32 validation, decompressor alloc/free.
Now used in both T1 streaming and Tmax parallel BGZF paths.

### Single-Member Sequential Path Is Already Optimal

Traced the T1/Tmax single-member decompression path: mmap → format detect → one
libdeflate call → one write → flush. No wasted work. T1 and Tmax use the identical
code path (can_parallelize=false for single-member). The 1-2% x86 noise gaps vs
rapidgzip/igzip on software/logs are pure measurement variance (55ms operations).

### BGZF deflate_start Must Handle FNAME/FCOMMENT

The `parse_bgzf_blocks` function's `deflate_start = offset + 12 + xlen` is WRONG when
gzip headers have FNAME (0x08), FCOMMENT (0x10), or FHCRC (0x02) flags set. Must parse
all optional fields to find the true deflate data offset.

## Remaining Gaps

### ACTIONABLE: None

All previously ACTIONABLE gaps have been closed or reclassified:
- `silesia-bgzf Tmax x86` vs rapidgzip: **CLOSED** (+6.6% ahead, 346.5 vs 325 MB/s)
- `silesia-gzip T1 x86` vs igzip: **CLOSED** (+5.1% ahead, 266.6 vs 253.6 MB/s)
- `software-bgzf T1 arm64` vs pigz: **NOISE** (24% swing between identical code runs)

### ARCHITECTURE (4 gaps, needs major feature)
- Silesia Tmax decompression vs rapidgzip only (10-16%)
- arm64 small-file Tmax gaps reclassified as NOISE (pigz decompresses sequentially)
- Requires rapidgzip-style pipeline (dedicated block-finder + decoder threads)
- Two-pass approach proven insufficient (scan pass overhead too high on 4 cores)

### Speculative Parallel (Feb 2026 — Evaluated, Infrastructure Ready)

Wired `speculative_parallel.rs` into production for Tmax single-member files.
Safety: ISIZE early check + CRC32 final check + fast fallback (<1ms overhead).

**Current status**: Always falls back to sequential on silesia data because the
block finder produces false positives. The precode leaf count check (rapidgzip
style) isn't sufficient to reject all false block starts in complex data.

**Why it fails**: The `validate_block_start` trial decode (256 symbols) isn't
selective enough. Random bit patterns in compressed data can form valid Huffman
tables that decode 256 symbols without error. Need either:
1. Much longer trial decode (4096+ symbols)
2. Entropy-based validation of decoded output
3. rapidgzip's full block-finder pipeline (13-bit LUT + multiple search stages)

**The infrastructure is safe and ready** — when the block finder improves, the
parallel path will activate automatically with no production code changes.

### SIMD (3 gaps, accepted)
- L1 compression vs igzip's AVX2/AVX-512 assembly

## CI Benchmark Architecture

**Platforms**: x86_64 (EPYC 4-core), arm64 (Graviton 4-core)
**Datasets**: silesia (211MB), software (~22MB), logs (~22MB)
**Archives**: gzip, bgzf, pigz — thread configs T1 and Tmax (4)
**Benchmark path**: `subprocess.run([tool, "-d"], stdin=fin, stdout=fout)` (stdin pipe, not file arg)
**Convergence**: min 10, max 40 trials, target CV <3%

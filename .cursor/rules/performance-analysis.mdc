---
description: CI-driven performance workflow — cloud fleet is the source of truth
alwaysApply: true
---

# Performance Analysis & Strategy (Feb 2026)

## Current Status: 41W / 19L (Cloud Fleet, Feb 21 2026)

### Decompression: 28 WINS / 12 LOSSES

**WINS (28):**
- BGZF: ALL 12 scenarios (T1 + Tmax, both arches) — gzippy is dominant
- arm64 non-BGZF T1: ALL 6 — +76-173% vs nearest competitor
- x86 T1: logs-gzip, logs-pigz — exact parity with igzip
- x86 T1: all BGZF — +7% to +100%+ vs igzip

**Near-parity (4 losses, <1% gap, measurement noise):**
- silesia-gzip T1: 594 vs igzip 597 (-0.5%)
- silesia-pigz T1: 550 vs igzip 556 (-1.0%)
- software-gzip T1: 2522 vs igzip 2528 (-0.2%)
- software-pigz T1: 2277 vs igzip 2293 (-0.7%)

**Tmax single-member (8 losses, -18% to -41%):**
No single-member parallel decompression. rapidgzip achieves 1.5-1.8x via
dedicated block-finder + decoder thread pipeline.

### Compression: 13 WINS / 7 LOSSES

**WINS:** ALL L6/L9, ALL silesia L1, ALL arm64 T1.

**Losses:**
- L1 T1 vs igzip (2): igzip AVX-512 assembly (-62% to -73%)
- L1/L6 Tmax scaling (5): pigz 3.5x vs gzippy 1.2-1.3x (-10% to -39%)

## Remaining Gaps Analysis

### Closable (13 losses)
| Gap | Approach |
|-----|----------|
| 4 x86 T1 decompress (<1%) | Already won — noise |
| 5 L1/L6 Tmax compress scaling | Reduce per-block overhead (hash init, headers, CRC32) |
| 4 of 8 Tmax decompress (short files) | Pipeline overhead may close for <50MB files |

### Hard to Close (6 losses)
| Gap | Why |
|-----|-----|
| 2 L1 T1 compress vs igzip | igzip uses AVX-512 hand-tuned assembly |
| 4 Tmax decompress (silesia 211MB) | Needs pipeline architecture (block-finder + decoder threads) |

## Benchmark Architecture

**Cloud fleet** (`gzippy-dev cloud bench`):
- 12 instances: 6 x86_64 (c7i.4xlarge) + 6 arm64 (c8g.4xlarge)
- 1 instance per (arch, dataset, direction) — fully parallel
- RAM-backed I/O (/dev/shm) isolates CPU from EBS
- Convergence: min 10, max 40 trials, target CV <3%
- Strict scoring: gzippy must be >= EVERY competitor or it's a loss

**Matrix**: 3 datasets × 3 archive types × 2 thread configs × 2 arches = 36 decompress + 36 compress = 72 scenarios.

## Proven Strategies

### What WORKS
| Approach | Result |
|---|---|
| Direct ISA-L FFI (bypass wrapper crates) | Exact parity with igzip on x86 T1 |
| BGZF-specific path at T1 | +31% (pre-parsed blocks, exact ISIZE alloc) |
| Pipelined BGZF streaming | 2.88x scaling |
| Per-thread reusable buffers | Stays in L2 cache |
| 1MB streaming output buffer | Avoids 50K page faults from large alloc |
| RAM-backed I/O (/dev/shm) | Reveals true CPU speed |
| Parallel fleet (1 per arch×dataset×direction) | High precision, full parallelism |

### What DOESN'T WORK
| Approach | Result |
|---|---|
| Speculative parallel decode | -15% to -86% regression on real data |
| Two-pass parallel (scan + re-decode) | 32% SLOWER (scan costs as much as full decode) |
| Finding deflate block boundaries | Success rate <5% |
| Pre-allocated full output + write_all | 50K page faults = 55ms sys overhead |
| isal-rs Decoder wrapper | 16KB internal buffer copies cost 2-8% |
| Assuming pigz = multi-member | pigz IS single-member |
| Simulation benchmarks | Always lie about real-world perf |
| Micro-optimizations in decode | LLVM already optimizes well at this level |

## Optimization History

### Phase 1: Compression Scaling (DONE)
Larger blocks (256KB→4MB), zero-copy stdin. Fixed L6/L9 scaling.
L1 Tmax still lags (per-block overhead dominates at L1 speed).

### Phase 2: Multi-Member Decompression (N/A)
Discovered pigz output is single-member. Implemented fast boundary scan
for actual multi-member files. pigz losses merge into Phase 4.

### Phase 3: ISA-L x86 T1 Decompression (DONE)
Three iterations to achieve igzip parity:
1. Buffered (full pre-alloc): -20% (page faults)
2. isal-rs Decoder streaming: -2% to -8% (wrapper overhead)
3. Direct isal_sys FFI: **exact parity** (zero overhead)

### Phase 4: Single-Member Parallel Decompression (OPEN)
8 Tmax losses remain. rapidgzip achieves 1.5-1.8x via dedicated
block-finder + decoder thread pipeline. All previous attempts
at speculative/two-pass parallel have regressed.

## Cloud Fleet Operations

```bash
source .env                          # AWS credentials
gzippy-dev cloud bench               # Launch fleet, benchmark, collect results
# Results in cloud-results.json
```

Fleet creates 12 instances, runs benchmarks in parallel, collects JSON results,
and terminates all instances + security groups on completion.

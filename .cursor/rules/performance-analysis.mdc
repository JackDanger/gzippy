---
description: CI-driven performance workflow — cloud fleet is the source of truth
alwaysApply: true
---

# Performance Workflow: Cloud Fleet Is the Source of Truth

## Core Principle

**Never trust local benchmarks for final decisions.** The cloud fleet runs on both
x86_64 (c7i Sapphire Rapids) and arm64 (c8g Graviton4) with RAM-backed I/O,
all datasets, archive types, thread configs, and competitors. Local runs are
useful for rapid iteration but the cloud fleet is authoritative.

**Never compromise performance under any conditions.** There is no threshold below
which a regression is acceptable. Never accept a clippy/lint suggestion in a hot path
without verifying identical codegen. Use `#[allow(clippy::...)]` to suppress lints
rather than changing code that might be slower. Every nanosecond counts.

## Full Benchmark Matrix

### Decompression: 3 datasets × 3 archives × 2 threads × 2 archs = 36 scenarios
| Axis | Values |
|------|--------|
| Datasets | silesia (211MB), software (~22MB), logs (~22MB) |
| Archive types | gzip (single-member), bgzf (gzippy format), pigz (single-member!) |
| Thread configs | T1 (1 thread), Tmax (4 on cloud fleet) |
| Architectures | x86_64 (c7i.4xlarge), arm64 (c8g.4xlarge) |
| Competitors | unpigz, igzip, rapidgzip, gzip |

### Compression: 3 datasets × 3 levels × 2 threads × 2 archs = 36 scenarios
| Axis | Values |
|------|--------|
| Datasets | silesia (211MB), software (~22MB), logs (~22MB) |
| Levels | L1 (speed), L6 (balanced), L9 (ratio) |
| Thread configs | T1 (1 thread), Tmax (4 on cloud fleet) |
| Architectures | x86_64 (c7i.4xlarge), arm64 (c8g.4xlarge) |
| Competitors | pigz, igzip (L1 only), gzip |

### Total: 72 scenarios (36 decompress + 36 compress)
Plus local Mac (arm64 Apple Silicon) for all scenarios = 108 total cells.

## Benchmarking Architecture (Feb 2026)

**ONE benchmark implementation**: `gzippy-dev bench` is THE authoritative benchmark.
It runs everywhere — local, cloud fleet, CI — with identical logic.

```
gzippy-dev bench                        # decompression, all datasets
gzippy-dev bench --direction compress   # compression benchmarks (L1, L6, L9)
gzippy-dev bench --direction both       # everything
gzippy-dev bench --json                 # machine-readable
gzippy-dev bench --dataset silesia      # one dataset
gzippy-dev bench --archive bgzf         # one archive type
gzippy-dev bench --threads 1            # T1 only
gzippy-dev bench --min-trials 50 --max-trials 200 --target-cv 0.005
```

**Cloud fleet** (`gzippy-dev cloud bench`):
- 12 instances: 6 x86_64 (c7i.4xlarge) + 6 arm64 (c8g.4xlarge)
- 1 instance per (arch, dataset, direction) — fully parallel
- Also runs local Mac benchmarks simultaneously (both directions)
- Two-phase: sweep (30-100 trials, CV<1.5%) + precision re-run close races
- Strict scoring: gzippy must be >= every competitor, or it's a loss
- Results dumped to `cloud-results.json` with per-scenario scorecard
- Wall time: ~20 min total (setup + benchmarks in parallel)

**Output**: `cloud-results.json` contains structured results with scorecard:
```json
{
  "wins": N, "losses": M, "total_scenarios": N+M,
  "scorecard": [{"scenario": "...", "verdict": "WIN/LOSS", "gap_pct": ...}],
  "results": [{"platform": "...", "dataset": "...", "direction": "...", ...}]
}
```

## The Loop

```
# ... make ONE focused code change ...
cargo test --release                  # 1. Correctness
# local benchmark to sanity-check
gzippy-dev cloud bench                # 2. Authoritative cloud fleet numbers
# read cloud-results.json for structured results
```

## Current Status: Decompression 18/36 Wins (Feb 20 2026)

### Decompression Wins
- **BGZF — ALL 12 WINS** (T1 + Tmax, both arches): +8% to +155% vs best
- **arm64 non-BGZF T1 — 6 WINS**: gzippy beats all competitors on ARM T1

### Decompression Losses (18)

**Category 1: x86 T1 vs igzip (6 losses)**
igzip's AVX-512 Huffman decode + vpclmulqdq CRC32 gives 2x on repetitive data.

**Category 2: All non-BGZF Tmax (12 losses)**
rapidgzip parallelizes single-member gzip. gzippy falls back to sequential.
Requires dedicated block-finder + decoder architecture (not yet implemented).

### Compression Status
Compression benchmarks now measured but not yet cloud-validated. Local Mac shows:
- T1: gzippy wins at all levels
- Tmax: gzippy loses to pigz at L1 (pigz has better thread scaling)

## Optimization History: What Works vs What Doesn't

### Strategies That WORK
| Approach | Result |
|---|---|
| Pipelined BGZF streaming | 2.88x scaling, +71-155% vs before |
| Per-thread reusable buffers | Stays in L2 cache |
| RAM-backed I/O (/dev/shm) | Reveals true CPU speed |
| Parallel fleet (1 per arch×dataset×direction) | Full parallelism, high precision |
| Local Mac in parallel with cloud | Free extra data point |
| JSON results dump | Easy to parse for analysis |

### Strategies That DON'T WORK
| Approach | Result |
|---|---|
| Two-pass parallel (scan + re-decode) | 32% SLOWER (scan cost too high at 4 cores) |
| Speculative parallel | Regressed arm64 by 15% |
| Simulation benchmarks | Always lie about real-world perf |
| EBS gp3 for benchmarks | 131 MB/s cap hides real differences |
| Micro-optimizations in decode | LLVM already optimizes well |
| Pre-allocated full output + serial write_all | 2x scaling, 53K page faults |
